{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ade338c",
   "metadata": {},
   "source": [
    "# GeoAI Hack - Locust Breeding Ground Prediction using HLS Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4574f053-60d4-419b-88cc-c58d08a8177c",
   "metadata": {
    "id": "4574f053-60d4-419b-88cc-c58d08a8177c"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/instadeepai/InstaGeo-E2E-Geospatial-ML/blob/main/notebooks/InstaGeo_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This starter notebook showcases the capabilities of InstaGeo, an end-to-end package designed for geospatial machine learning with multispectral data.\n",
    "\n",
    "In this demonstration, we use ground-truth locust observations downloaded from the [UN FAO Locust Hub ](https://locust-hub-hqfao.hub.arcgis.com/) on March 17, 2022 to learn a model for identifying desert locust breeding grounds in Africa. The notebook will guide you through the process of creating segmentation-like data from these observations, fine-tuning the [Prithvi](https://huggingface.co/ibm-nasa-geospatial/Prithvi-100M) model, and finally visualizing the inference results on an interactive map.\n",
    "\n",
    "By the end of this demo, you will gain hands-on experience with key InstaGeo functionalities and learn how it streamlines geospatial ML workflows from data preparation to model inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380ead2a",
   "metadata": {
    "id": "380ead2a"
   },
   "source": [
    "# Install InstaGeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e550a300",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e550a300",
    "outputId": "01be6d02-d659-421f-b382-98e093bfd8b1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'InstaGeo-E2E-Geospatial-ML'...\n",
      "remote: Enumerating objects: 363, done.\u001b[K\n",
      "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
      "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
      "remote: Total 363 (delta 125), reused 110 (delta 67), pack-reused 162 (from 1)\u001b[K\n",
      "Receiving objects: 100% (363/363), 1.43 MiB | 1.75 MiB/s, done.\n",
      "Resolving deltas: 100% (192/192), done.\n"
     ]
    }
   ],
   "source": [
    "repository_url = \"https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML\"\n",
    "\n",
    "!git clone {repository_url}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f7e762b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "9f7e762b",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "83e1756d-4ee7-4eb2-ded4-f613973ec8c6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/instageo_wxc/InstaGeo-E2E-Geospatial-ML\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Checking if build backend supports build_editable: started\n",
      "  Checking if build backend supports build_editable: finished with status 'done'\n",
      "  Getting requirements to build editable: started\n",
      "  Getting requirements to build editable: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing editable metadata (pyproject.toml): started\n",
      "  Preparing editable metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: pandas in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.2.3)\n",
      "Requirement already satisfied: numpy in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.1.3)\n",
      "Requirement already satisfied: xarray[complete] in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2025.1.1)\n",
      "Requirement already satisfied: rasterio in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (1.4.3)\n",
      "Requirement already satisfied: rioxarray in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (0.18.2)\n",
      "Requirement already satisfied: geopandas==0.14.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (0.14.1)\n",
      "Requirement already satisfied: shapely in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.0.6)\n",
      "Requirement already satisfied: cftime in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (1.6.4.post1)\n",
      "Requirement already satisfied: h5pyd in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (0.21.0)\n",
      "Requirement already satisfied: Bottleneck in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: absl-py in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.1.0)\n",
      "Requirement already satisfied: mgrs==1.4.6 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (1.4.6)\n",
      "Collecting earthaccess==0.12.0 (from instageo==0.0.1)\n",
      "  Downloading earthaccess-0.12.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting pydantic==2.10.4 (from instageo==0.0.1)\n",
      "  Downloading pydantic-2.10.4-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting pydantic-settings==2.7.0 (from instageo==0.0.1)\n",
      "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting python-dotenv==1.0.1 (from instageo==0.0.1)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pystac_client==0.8.5 (from instageo==0.0.1)\n",
      "  Downloading pystac_client-0.8.5-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting stackstac==0.5.1 (from instageo==0.0.1)\n",
      "  Downloading stackstac-0.5.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting planetary_computer==1.0.0 (from instageo==0.0.1)\n",
      "  Downloading planetary_computer-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: pytorch_lightning in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.5.0.post0)\n",
      "Requirement already satisfied: torch in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (2.6.0)\n",
      "Collecting timm==0.4.12 (from instageo==0.0.1)\n",
      "  Downloading timm-0.4.12-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting einops (from instageo==0.0.1)\n",
      "  Downloading einops-0.8.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting tensorboard (from instageo==0.0.1)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting hydra-core (from instageo==0.0.1)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting omegaconf (from instageo==0.0.1)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting plotly (from instageo==0.0.1)\n",
      "  Downloading plotly-6.0.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting datashader==0.16.2 (from instageo==0.0.1)\n",
      "  Downloading datashader-0.16.2-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Collecting dask==2024.12.1 (from instageo==0.0.1)\n",
      "  Downloading dask-2024.12.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: matplotlib in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from instageo==0.0.1) (3.10.0)\n",
      "Collecting streamlit==1.31.1 (from instageo==0.0.1)\n",
      "  Downloading streamlit-1.31.1-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: click>=8.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (2023.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (24.2)\n",
      "Requirement already satisfied: partd>=1.4.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (6.0.2)\n",
      "Requirement already satisfied: toolz>=0.10.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (1.0.0)\n",
      "Collecting colorcet (from datashader==0.16.2->instageo==0.0.1)\n",
      "  Downloading colorcet-3.1.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting multipledispatch (from datashader==0.16.2->instageo==0.0.1)\n",
      "  Downloading multipledispatch-1.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numba in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from datashader==0.16.2->instageo==0.0.1) (0.61.0)\n",
      "Collecting param (from datashader==0.16.2->instageo==0.0.1)\n",
      "  Downloading param-2.2.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pillow in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from datashader==0.16.2->instageo==0.0.1) (11.1.0)\n",
      "Collecting pyct (from datashader==0.16.2->instageo==0.0.1)\n",
      "  Downloading pyct-0.5.0-py2.py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: requests in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from datashader==0.16.2->instageo==0.0.1) (2.32.3)\n",
      "Requirement already satisfied: scipy in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from datashader==0.16.2->instageo==0.0.1) (1.15.1)\n",
      "Requirement already satisfied: importlib-resources>=6.3.2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (6.5.2)\n",
      "Requirement already satisfied: multimethod>=1.8 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (2.0)\n",
      "Requirement already satisfied: pqdm>=0.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (0.2.0)\n",
      "Requirement already satisfied: python-cmr>=0.10.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (0.13.0)\n",
      "Requirement already satisfied: s3fs>=2022.11 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (2023.12.2)\n",
      "Requirement already satisfied: tinynetrc>=1.3.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from earthaccess==0.12.0->instageo==0.0.1) (4.12.2)\n",
      "Requirement already satisfied: fiona>=1.8.21 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from geopandas==0.14.1->instageo==0.0.1) (1.10.1)\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from geopandas==0.14.1->instageo==0.0.1) (3.7.0)\n",
      "Collecting pystac>=1.0.0 (from planetary_computer==1.0.0->instageo==0.0.1)\n",
      "  Downloading pystac-1.12.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pytz>=2020.5 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from planetary_computer==1.0.0->instageo==0.0.1) (2024.2)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic==2.10.4->instageo==0.0.1)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic==2.10.4->instageo==0.0.1)\n",
      "  Downloading pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pystac_client==0.8.5->instageo==0.0.1) (2.9.0.post0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (5.5.1)\n",
      "Collecting importlib-metadata<8,>=1.4 (from streamlit==1.31.1->instageo==0.0.1)\n",
      "  Downloading importlib_metadata-7.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting numpy (from instageo==0.0.1)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting packaging>=20.0 (from dask==2024.12.1->instageo==0.0.1)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pillow (from datashader==0.16.2->instageo==0.0.1)\n",
      "  Downloading pillow-10.4.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
      "Collecting protobuf<5,>=3.20 (from streamlit==1.31.1->instageo==0.0.1)\n",
      "  Downloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (19.0.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (13.9.4)\n",
      "Collecting tenacity<9,>=8.1.0 (from streamlit==1.31.1->instageo==0.0.1)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (0.10.2)\n",
      "Collecting tzlocal<6,>=1.1 (from streamlit==1.31.1->instageo==0.0.1)\n",
      "  Using cached tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting validators<1,>=0.2 (from streamlit==1.31.1->instageo==0.0.1)\n",
      "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from streamlit==1.31.1->instageo==0.0.1) (6.4.2)\n",
      "Collecting torchvision (from timm==0.4.12->instageo==0.0.1)\n",
      "  Downloading torchvision-0.21.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pandas->instageo==0.0.1) (2025.1)\n",
      "Requirement already satisfied: affine in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (2.4.0)\n",
      "Requirement already satisfied: attrs in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (25.1.0)\n",
      "Requirement already satisfied: certifi in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (2024.12.14)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (0.7.2)\n",
      "Requirement already satisfied: click-plugins in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rasterio->instageo==0.0.1) (3.2.1)\n",
      "Requirement already satisfied: filelock in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from torch->instageo==0.0.1) (3.17.0)\n",
      "Requirement already satisfied: networkx in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from torch->instageo==0.0.1) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from torch->instageo==0.0.1) (3.1.5)\n",
      "Requirement already satisfied: setuptools in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from torch->instageo==0.0.1) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from torch->instageo==0.0.1) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from sympy==1.13.1->torch->instageo==0.0.1) (1.3.0)\n",
      "INFO: pip is looking at multiple versions of h5pyd to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting h5pyd (from instageo==0.0.1)\n",
      "  Downloading h5pyd-0.20.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading h5pyd-0.19.0-py3-none-any.whl.metadata (1.9 kB)\n",
      "  Downloading h5pyd-0.18.0.tar.gz (139 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests_unixsocket in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from h5pyd->instageo==0.0.1) (0.3.0)\n",
      "Requirement already satisfied: pyjwt in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from h5pyd->instageo==0.0.1) (2.10.1)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core->instageo==0.0.1)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from matplotlib->instageo==0.0.1) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from matplotlib->instageo==0.0.1) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from matplotlib->instageo==0.0.1) (4.55.7)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from matplotlib->instageo==0.0.1) (1.4.8)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from plotly->instageo==0.0.1) (1.24.1)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pytorch_lightning->instageo==0.0.1) (4.67.1)\n",
      "Requirement already satisfied: torchmetrics>=0.7.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pytorch_lightning->instageo==0.0.1) (1.6.1)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pytorch_lightning->instageo==0.0.1) (0.12.0)\n",
      "Collecting grpcio>=1.48.2 (from tensorboard->instageo==0.0.1)\n",
      "  Downloading grpcio-1.70.0-cp313-cp313-macosx_10_14_universal2.whl.metadata (3.9 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->instageo==0.0.1)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: six>1.9 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from tensorboard->instageo==0.0.1) (1.17.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->instageo==0.0.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard->instageo==0.0.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from altair<6,>=4.0->streamlit==1.31.1->instageo==0.0.1) (4.23.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (3.11.11)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.31.1->instageo==0.0.1) (4.0.12)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<8,>=1.4->streamlit==1.31.1->instageo==0.0.1)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: locket in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from partd>=1.4.0->dask==2024.12.1->instageo==0.0.1) (1.0.0)\n",
      "Requirement already satisfied: bounded-pool-executor in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pqdm>=0.1->earthaccess==0.12.0->instageo==0.0.1) (0.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from jinja2->torch->instageo==0.0.1) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from requests->datashader==0.16.2->instageo==0.0.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from requests->datashader==0.16.2->instageo==0.0.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from requests->datashader==0.16.2->instageo==0.0.1) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.31.1->instageo==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from rich<14,>=10.14.0->streamlit==1.31.1->instageo==0.0.1) (2.19.1)\n",
      "Requirement already satisfied: aiobotocore<3.0.0,>=2.5.4 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (2.19.0)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from numba->datashader==0.16.2->instageo==0.0.1) (0.44.0)\n",
      "Requirement already satisfied: numbagg in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (0.8.2)\n",
      "Requirement already satisfied: flox in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (0.10.0)\n",
      "Requirement already satisfied: opt_einsum in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (3.4.0)\n",
      "Requirement already satisfied: netCDF4 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (1.7.2)\n",
      "Requirement already satisfied: h5netcdf in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: zarr in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (3.0.1)\n",
      "Requirement already satisfied: pooch in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (1.8.2)\n",
      "Requirement already satisfied: sparse in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (0.15.5)\n",
      "Requirement already satisfied: cartopy in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (0.24.1)\n",
      "Requirement already satisfied: nc-time-axis in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: seaborn in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from xarray[complete]->instageo==0.0.1) (0.13.2)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.36.4,>=1.36.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (1.36.3)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (1.0.1)\n",
      "Requirement already satisfied: multidict<7.0.0,>=6.0.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (6.1.0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess==0.12.0->instageo==0.0.1) (1.17.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning->instageo==0.0.1) (1.18.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit==1.31.1->instageo==0.0.1) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->instageo==0.0.1) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->instageo==0.0.1) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit==1.31.1->instageo==0.0.1) (0.22.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit==1.31.1->instageo==0.0.1) (0.1.2)\n",
      "Requirement already satisfied: pyshp>=2.3 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from cartopy->xarray[complete]->instageo==0.0.1) (2.3.1)\n",
      "Requirement already satisfied: lz4>=4.3.2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (4.4.3)\n",
      "Requirement already satisfied: numpy_groupies>=0.9.19 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from flox->xarray[complete]->instageo==0.0.1) (0.11.2)\n",
      "Requirement already satisfied: h5py in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from h5netcdf->xarray[complete]->instageo==0.0.1) (3.12.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from pooch->xarray[complete]->instageo==0.0.1) (4.3.6)\n",
      "Requirement already satisfied: donfig>=0.8 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from zarr->xarray[complete]->instageo==0.0.1) (0.8.1.post1)\n",
      "Requirement already satisfied: numcodecs>=0.14 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from numcodecs[crc32c]>=0.14->zarr->xarray[complete]->instageo==0.0.1) (0.15.0)\n",
      "Requirement already satisfied: deprecated in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from numcodecs>=0.14->numcodecs[crc32c]>=0.14->zarr->xarray[complete]->instageo==0.0.1) (1.2.18)\n",
      "Requirement already satisfied: crc32c>=2.7 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from numcodecs[crc32c]>=0.14->zarr->xarray[complete]->instageo==0.0.1) (2.7.1)\n",
      "Collecting dask-expr<1.2,>=1.1 (from dask==2024.12.1->instageo==0.0.1)\n",
      "  Downloading dask_expr-1.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting distributed==2024.12.1 (from dask==2024.12.1->instageo==0.0.1)\n",
      "  Downloading distributed-2024.12.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: bokeh>=3.1.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from dask==2024.12.1->instageo==0.0.1) (3.6.2)\n",
      "Requirement already satisfied: msgpack>=1.0.2 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from distributed==2024.12.1->dask==2024.12.1->instageo==0.0.1) (1.1.0)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from distributed==2024.12.1->dask==2024.12.1->instageo==0.0.1) (6.1.1)\n",
      "Requirement already satisfied: sortedcontainers>=2.0.5 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from distributed==2024.12.1->dask==2024.12.1->instageo==0.0.1) (2.4.0)\n",
      "Requirement already satisfied: tblib>=1.6.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from distributed==2024.12.1->dask==2024.12.1->instageo==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: zict>=3.0.0 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from distributed==2024.12.1->dask==2024.12.1->instageo==0.0.1) (3.0.0)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /Users/hakimdiouane/Documents/desert_locust_breeding_detection/benchmark_desert_locust_detection/Desert_Locust_Breeding_Detection/.env/lib/python3.13/site-packages (from bokeh>=3.1.0->dask==2024.12.1->instageo==0.0.1) (2025.1.0)\n",
      "Downloading dask-2024.12.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datashader-0.16.2-py2.py3-none-any.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading earthaccess-0.12.0-py3-none-any.whl (60 kB)\n",
      "Downloading planetary_computer-1.0.0-py3-none-any.whl (14 kB)\n",
      "Downloading pydantic-2.10.4-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
      "Downloading pystac_client-0.8.5-py3-none-any.whl (41 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading stackstac-0.5.1-py3-none-any.whl (64 kB)\n",
      "Downloading streamlit-1.31.1-py2.py3-none-any.whl (8.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading timm-0.4.12-py3-none-any.whl (376 kB)\n",
      "Downloading pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
      "Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Downloading plotly-6.0.0-py3-none-any.whl (14.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading grpcio-1.70.0-cp313-cp313-macosx_10_14_universal2.whl (11.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading importlib_metadata-7.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pillow-10.4.0-cp313-cp313-macosx_11_0_arm64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.6-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Downloading pystac-1.12.1-py3-none-any.whl (194 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading colorcet-3.1.0-py3-none-any.whl (260 kB)\n",
      "Downloading multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading param-2.2.0-py3-none-any.whl (119 kB)\n",
      "Downloading pyct-0.5.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading torchvision-0.21.0-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading distributed-2024.12.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dask_expr-1.1.21-py3-none-any.whl (244 kB)\n",
      "Building wheels for collected packages: instageo, numpy, h5pyd, antlr4-python3-runtime\n",
      "  Building editable for instageo (pyproject.toml): started\n",
      "  Building editable for instageo (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for instageo: filename=instageo-0.0.1-0.editable-py3-none-any.whl size=10013 sha256=7d229daa58fdff8b2c50e1a5c4a2e30963d89ecf3e283b746c583e2489dc454c\n",
      "  Stored in directory: /private/var/folders/nd/6d7z70s12vxdq276hh5_45z80000gn/T/pip-ephem-wheel-cache-n8khfq2g/wheels/68/65/87/2d29c5fdee3529cda520043457021a1d8ac74a8e9cf2126b42\n",
      "  Building wheel for numpy (pyproject.toml): started\n",
      "  Building wheel for numpy (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for numpy: filename=numpy-1.26.4-cp313-cp313-macosx_14_0_arm64.whl size=4680577 sha256=645166488334eceb7de7a32c4971ee7827469bfe87e84547c99d8cbfe0f7a8f6\n",
      "  Stored in directory: /Users/hakimdiouane/Library/Caches/pip/wheels/8b/2d/9f/b6b46373f328e2ef50388915d351ccacbedac929459b5459bf\n",
      "  Building wheel for h5pyd (pyproject.toml): started\n",
      "  Building wheel for h5pyd (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for h5pyd: filename=h5pyd-0.18.0-py3-none-any.whl size=169301 sha256=4254f488e02c7101d71717036dddbfb1296609ce3c17d644ce4ac1b13e4c3e25\n",
      "  Stored in directory: /Users/hakimdiouane/Library/Caches/pip/wheels/26/6f/68/32aedb362174517262fcf6f98161a482135626f3692bea8230\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): started\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=8a90e880782bedc1203096adb710de2d8b54c8ce0de69888f5f4c31645ce4dfa\n",
      "  Stored in directory: /Users/hakimdiouane/Library/Caches/pip/wheels/d5/b3/74/a35b66048c9de6631cd74cbc9475e6feb3e69a467983446bd8\n",
      "Successfully built instageo numpy h5pyd antlr4-python3-runtime\n",
      "Installing collected packages: multipledispatch, antlr4-python3-runtime, zipp, werkzeug, validators, tzlocal, tensorboard-data-server, tenacity, python-dotenv, pydantic-core, protobuf, pillow, param, packaging, omegaconf, numpy, markdown, grpcio, einops, colorcet, annotated-types, tensorboard, pystac, pydantic, pyct, plotly, importlib-metadata, hydra-core, dask, torchvision, pydantic-settings, h5pyd, distributed, dask-expr, timm, stackstac, datashader, streamlit, pystac_client, earthaccess, planetary_computer, instageo\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 5.29.3\n",
      "    Uninstalling protobuf-5.29.3:\n",
      "      Successfully uninstalled protobuf-5.29.3\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.1.0\n",
      "    Uninstalling pillow-11.1.0:\n",
      "      Successfully uninstalled pillow-11.1.0\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "  Attempting uninstall: dask\n",
      "    Found existing installation: dask 2025.1.0\n",
      "    Uninstalling dask-2025.1.0:\n",
      "      Successfully uninstalled dask-2025.1.0\n",
      "  Attempting uninstall: h5pyd\n",
      "    Found existing installation: h5pyd 0.21.0\n",
      "    Uninstalling h5pyd-0.21.0:\n",
      "      Successfully uninstalled h5pyd-0.21.0\n",
      "  Attempting uninstall: distributed\n",
      "    Found existing installation: distributed 2025.1.0\n",
      "    Uninstalling distributed-2025.1.0:\n",
      "      Successfully uninstalled distributed-2025.1.0\n",
      "  Attempting uninstall: streamlit\n",
      "    Found existing installation: streamlit 1.41.1\n",
      "    Uninstalling streamlit-1.41.1:\n",
      "      Successfully uninstalled streamlit-1.41.1\n",
      "  Attempting uninstall: earthaccess\n",
      "    Found existing installation: earthaccess 0.8.2\n",
      "    Uninstalling earthaccess-0.8.2:\n",
      "      Successfully uninstalled earthaccess-0.8.2\n",
      "Successfully installed annotated-types-0.7.0 antlr4-python3-runtime-4.9.3 colorcet-3.1.0 dask-2024.12.1 dask-expr-1.1.21 datashader-0.16.2 distributed-2024.12.1 earthaccess-0.12.0 einops-0.8.0 grpcio-1.70.0 h5pyd-0.18.0 hydra-core-1.3.2 importlib-metadata-7.2.1 instageo-0.0.1 markdown-3.7 multipledispatch-1.0.0 numpy-1.26.4 omegaconf-2.3.0 packaging-23.2 param-2.2.0 pillow-10.4.0 planetary_computer-1.0.0 plotly-6.0.0 protobuf-4.25.6 pyct-0.5.0 pydantic-2.10.4 pydantic-core-2.27.2 pydantic-settings-2.7.0 pystac-1.12.1 pystac_client-0.8.5 python-dotenv-1.0.1 stackstac-0.5.1 streamlit-1.31.1 tenacity-8.5.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 timm-0.4.12 torchvision-0.21.0 tzlocal-5.2 validators-0.34.0 werkzeug-3.1.3 zipp-3.21.0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd InstaGeo-E2E-Geospatial-ML\n",
    "pip install -e .[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238c78e7-720e-49ed-b5ce-6be6567d2585",
   "metadata": {
    "id": "238c78e7-720e-49ed-b5ce-6be6567d2585"
   },
   "source": [
    "## EarthData Login\n",
    "\n",
    "InstaGeo currently supports multispectral data from NASA [Harmonized Landsat and Sentinel-2 (HLS)](https://hls.gsfc.nasa.gov/). Accessing HLS data requires an EarthData user account which can be created [here](https://urs.earthdata.nasa.gov/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc7ff9c",
   "metadata": {
    "id": "4fc7ff9c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b7a5f61",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8b7a5f61",
    "outputId": "74e752c9-e666-4363-b02f-66a0780fc240",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter you EarthData user account credentials\n",
    "USERNAME = \"hakdiouane\"\n",
    "PASSWORD = \"DesertLocustHackathon2025@\"\n",
    "\n",
    "content = f\"\"\"machine urs.earthdata.nasa.gov login {USERNAME} password {PASSWORD}\"\"\"\n",
    "\n",
    "with open(os.path.expanduser('~/.netrc'), 'w') as file:\n",
    "    file.write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488a15d3-f22e-4b2c-85c0-435c832e708c",
   "metadata": {
    "id": "488a15d3-f22e-4b2c-85c0-435c832e708c"
   },
   "source": [
    "## InstaGeo - Data (Optional)\n",
    "\n",
    "With InstaGeo installed and EarthData authentication configured, we are now ready to download and process HLS (Harmonized Landsat and Sentinel) granules using the `InstaGeo-Data` module. This module offers several powerful functionalities for handling geospatial data, including:\n",
    "\n",
    "- Searching and retrieving metadata for HLS granules\n",
    "- Downloading specific spectral bands from HLS granules\n",
    "- Generating data chips and corresponding target labels for machine learning tasks\n",
    "\n",
    "These capabilities streamline the preprocessing of multispectral data, setting the foundation for efficient geospatial model development.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38e36f50",
   "metadata": {
    "id": "38e36f50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d83f72",
   "metadata": {
    "id": "c4d83f72"
   },
   "source": [
    "The ground-truth locust observations used in this challenge were downloaded from the [UN FAO Locust Hub ](https://locust-hub-hqfao.hub.arcgis.com/) on March 17, 2022. The raw data was processed to derive our locust breeding ground dataset. The label dataset was splitted into train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc545f4",
   "metadata": {
    "id": "fcc545f4"
   },
   "source": [
    "After splitting the data into training and test splits, the next step is to group the data by the HLS granules they belong to and download the corresponding spectral bands for each granule. Once the bands are retrieved, we will generate smaller chips and target labels with dimensions of 256 x 256 pixels.\n",
    "\n",
    "By the end of this process, the input data will have a shape of 3 x 6 x 256 x 256 (representing three sets of six spectral bands and 256 x 256 pixel chips), and the target labels will have a shape of 256 x 256.\n",
    "\n",
    "While these tasks might seem complex, the `InstaGeo-Data` module abstracts this process, allowing you to configure it with a simple command as shown in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16bdb6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_mapping(root_dir, input_subdir, output_csv):\n",
    "    \"\"\"\n",
    "    Generate a CSV mapping input chips to corresponding segmentation maps.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str or Path): Root directory containing the subdirectories for chips and segmentation maps.\n",
    "        input_subdir (str): Subdirectory path for chips within the root directory.\n",
    "        output_csv (str or Path): Output path for the generated CSV file.\n",
    "    \"\"\"\n",
    "    root_dir = Path(root_dir)\n",
    "    chips_orig = os.listdir(root_dir / input_subdir / \"chips\")\n",
    "\n",
    "    chips = [chip.replace(\"chip\", f\"{input_subdir}/chips/chip\") for chip in chips_orig]\n",
    "    seg_maps = [chip.replace(\"chip\", f\"{input_subdir}/seg_maps/seg_map\") for chip in chips_orig]\n",
    "\n",
    "    df = pd.DataFrame({\"Input\": chips, \"Label\": seg_maps})\n",
    "    df.to_csv(root_dir / output_csv, index=False)\n",
    "    \n",
    "    print(f\"Number of rows is: {df.shape[0]}\")\n",
    "    print(f\"CSV generated and saved to: {root_dir / output_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b901a48e",
   "metadata": {
    "id": "b901a48e"
   },
   "source": [
    "### Training Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bfeb8-df6b-4b8c-8c8a-059a5a28b8ea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "c11bfeb8-df6b-4b8c-8c8a-059a5a28b8ea",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "2b68bdfe-c648-44ed-c121-02177df206fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir train\n",
    "\n",
    "!python -m \"instageo.data.chip_creator\" \\\n",
    "    --dataframe_path=\"train.csv\" \\\n",
    "    --output_directory=\"train\" \\\n",
    "    --min_count=10 \\\n",
    "    --chip_size=256 \\\n",
    "    --temporal_tolerance=3 \\\n",
    "    --temporal_step=30 \\\n",
    "    --num_steps=3 \\\n",
    "    --masking_strategy=any \\\n",
    "    --mask_types=water \\\n",
    "    --window_size=3 \\\n",
    "    --processing_method=cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22FADUFcfYsR",
   "metadata": {
    "id": "22FADUFcfYsR"
   },
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), \"train\", \"train_ds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4e7fa6",
   "metadata": {
    "id": "3d4e7fa6"
   },
   "source": [
    "### Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_xaa5V3sf3pJ",
   "metadata": {
    "id": "_xaa5V3sf3pJ"
   },
   "outputs": [],
   "source": [
    "!mkdir test\n",
    "\n",
    "!python -m \"instageo.data.chip_creator\" \\\n",
    "    --dataframe_path=\"test.csv\" \\\n",
    "    --output_directory=\"test\" \\\n",
    "    --min_count=1 \\\n",
    "    --chip_size=256 \\\n",
    "    --temporal_tolerance=3 \\\n",
    "    --temporal_step=30 \\\n",
    "    --num_steps=3 \\\n",
    "    --masking_strategy=any \\\n",
    "    --mask_types=water \\\n",
    "    --processing_method=cog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XYrUAef1mJ0N",
   "metadata": {
    "id": "XYrUAef1mJ0N"
   },
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), \"test\", \"test_ds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6ef759",
   "metadata": {},
   "source": [
    "## Prepare Data\n",
    "\n",
    "Due to the limited time available for this hackathon, we have created the chips and labels using `Instageo-Data`, which took 57h to complete.\n",
    "\n",
    "The data is provided as part of this competition. So you can simply download it and start hacking your way to a TOP SOLUTION!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a4ba26",
   "metadata": {},
   "source": [
    "Extract the compressed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d7725",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf train.tar.gz\n",
    "!tar -xvzf test.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9ebec",
   "metadata": {},
   "source": [
    "Create input and label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c6ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_mapping(root_dir, input_subdir, output_csv):\n",
    "    \"\"\"\n",
    "    Generate a CSV mapping input chips to corresponding segmentation maps.\n",
    "\n",
    "    Args:\n",
    "        root_dir (str or Path): Root directory containing the subdirectories for chips and segmentation maps.\n",
    "        input_subdir (str): Subdirectory path for chips within the root directory.\n",
    "        output_csv (str or Path): Output path for the generated CSV file.\n",
    "    \"\"\"\n",
    "    root_dir = Path(root_dir)\n",
    "    chips_orig = os.listdir(root_dir / input_subdir / \"chips\")\n",
    "\n",
    "    chips = [chip.replace(\"chip\", f\"{input_subdir}/chips/chip\") for chip in chips_orig]\n",
    "    seg_maps = [chip.replace(\"chip\", f\"{input_subdir}/seg_maps/seg_map\") for chip in chips_orig]\n",
    "\n",
    "    df = pd.DataFrame({\"Input\": chips, \"Label\": seg_maps})\n",
    "    df.to_csv(root_dir / output_csv, index=False)\n",
    "    \n",
    "    print(f\"Number of rows is: {df.shape[0]}\")\n",
    "    print(f\"CSV generated and saved to: {root_dir / output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d992337",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), 'train', \"train_ds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbcb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), 'test', \"test_ds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3955a5",
   "metadata": {},
   "source": [
    "Split out Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_validation_data(mapping_csv, data_dir, train_dir, validation_dir, validation_split=0.3):\n",
    "    \"\"\"\n",
    "    Split data into training and validation sets based on a CSV file mapping `chips` and `seg_maps`.\n",
    "\n",
    "    Args:\n",
    "        mapping_csv (str or Path): Path to the CSV file containing the mapping between `chips` and `seg_maps`.\n",
    "        data_dir (str or Path): Path to the merged directory containing all files.\n",
    "        validation_dir (str or Path): Path to the new directory for validation files.\n",
    "        validation_split (float): Fraction of the data to use as the validation set.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    validation_dir = Path(validation_dir)\n",
    "    train_dir = Path(train_dir)\n",
    "\n",
    "    validation_dir.mkdir(parents=True, exist_ok=True)\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df = pd.read_csv(mapping_csv)\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    num_val = int(len(df) * validation_split)\n",
    "    train_df = df[num_val:]\n",
    "    val_df = df[:num_val]\n",
    "\n",
    "    for _, row in val_df.iterrows():\n",
    "        chip_file = data_dir / Path(row['Input']).relative_to(data_dir)\n",
    "        seg_map_file = data_dir / Path(row['Label']).relative_to(data_dir)\n",
    "\n",
    "        for file, subfolder in [(chip_file, \"chips\"), (seg_map_file, \"seg_maps\")]:\n",
    "            if file.exists():\n",
    "                dest_path = validation_dir / subfolder / file.relative_to(data_dir).name\n",
    "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(file), str(dest_path))\n",
    "            else:\n",
    "                print(f\"File not found: {file}\")\n",
    "                \n",
    "    for _, row in train_df.iterrows():\n",
    "        chip_file = data_dir / Path(row['Input']).relative_to(data_dir)\n",
    "        seg_map_file = data_dir / Path(row['Label']).relative_to(data_dir)\n",
    "\n",
    "        for file, subfolder in [(chip_file, \"chips\"), (seg_map_file, \"seg_maps\")]:\n",
    "            if file.exists():\n",
    "                dest_path = train_dir / subfolder / file.relative_to(data_dir).name\n",
    "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.move(str(file), str(dest_path))\n",
    "            else:\n",
    "                print(f\"File not found: {file}\")\n",
    "                \n",
    "    print(f\"Train files moved to {train_dir}. Train set size: {len(train_df)}.\")\n",
    "    print(f\"Validation files moved to {validation_dir}. Validation set size: {len(val_df)}.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1303180",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_validation_data(\n",
    "    mapping_csv=\"train_ds.csv\",\n",
    "    data_dir=\"train_split\",\n",
    "    validation_dir=\"validation_split\",\n",
    "    validation_split=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate label mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), 'train_split', \"train_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c014320",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_label_mapping(Path.cwd(), 'validation_split', \"validation_split.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb132b0-04dd-4583-8e30-e6332446a0e6",
   "metadata": {
    "id": "bcb132b0-04dd-4583-8e30-e6332446a0e6"
   },
   "source": [
    "## InstaGeo - Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd313044-829c-482d-934e-9ae662f132fc",
   "metadata": {
    "id": "fd313044-829c-482d-934e-9ae662f132fc"
   },
   "source": [
    "After creating our dataset using the `InstaGeo-Data` module, we can move on to fine-tuning a model that includes a Prithvi backbone paired with a classification head. For regression tasks, the classification head can easily be replaced with a suitable regression head. Additionally, if a completely different model architecture is needed, it can be designed and implemented within this framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64fee29-dca3-4611-a43a-4412a6033751",
   "metadata": {
    "id": "c64fee29-dca3-4611-a43a-4412a6033751"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115cbc92",
   "metadata": {
    "id": "115cbc92"
   },
   "source": [
    "**Launch Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad3672a",
   "metadata": {},
   "source": [
    "First compute the mean and standard deviation for the dataset and update the corresponding config file, in this case `locust.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b4a042-ab38-470f-ad02-3dd67ddda0c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m instageo.model.run --config-name=locust \\\n",
    "    root_dir='.' \\\n",
    "    train.batch_size=8 \\\n",
    "    train.num_epochs=5 \\\n",
    "    mode=stats \\\n",
    "    train_filepath=\"train_ds.csv\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1264ca12",
   "metadata": {},
   "source": [
    "Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m instageo.model.run --config-name=locust \\\n",
    "    root_dir='.' \\\n",
    "    train.batch_size=8 \\\n",
    "    train.num_epochs=5 \\\n",
    "    mode=train \\\n",
    "    train_filepath=\"train_ds.csv\" \\\n",
    "    valid_filepath=\"val_ds.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10db019e",
   "metadata": {
    "id": "10db019e"
   },
   "source": [
    "**Run Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67acf232",
   "metadata": {
    "id": "67acf232"
   },
   "source": [
    "Adjust the `checkpoint_path` argument to use the desired model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8230588-2842-460c-b2e7-4f2f4175dc3e",
   "metadata": {
    "collapsed": true,
    "id": "f8230588-2842-460c-b2e7-4f2f4175dc3e",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m instageo.model.run --config-name=locust \\\n",
    "    root_dir='.' \\\n",
    "    test_filepath=\"test_ds.csv\" \\\n",
    "    train.batch_size=8 \\\n",
    "    checkpoint_path='checkpoint-path' \\\n",
    "    mode=eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3646bd",
   "metadata": {},
   "source": [
    "### Make Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3070575a",
   "metadata": {},
   "source": [
    "We first run inference on test chips to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed1ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m instageo.model.run --config-name=locust \\\n",
    "    root_dir='.' \\\n",
    "    test_filepath=\"test_ds.csv\" \\\n",
    "    train.batch_size=16 \\\n",
    "    checkpoint_path='checkpoint_path' \\\n",
    "    mode=chip_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642710d0",
   "metadata": {},
   "source": [
    "After getting the prdictions for each chip, we retrieve the predicted value for each observatio in our test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165da191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS, Transformer\n",
    "import os\n",
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "predictions_directory = \"predictions\"\n",
    "prediction_files = os.listdir(predictions_directory)\n",
    "\n",
    "def get_prediction_value(row):\n",
    "    matching_files = [f for f in prediction_files if (str(row['date']) in f) and (row['mgrs_tile_id'] in f)]\n",
    "    if not matching_files:\n",
    "        return (np.nan, np.nan)\n",
    "    for file in matching_files:\n",
    "        with rasterio.open(f\"{predictions_directory}/{file}\") as src:\n",
    "            width, height = src.width, src.height\n",
    "            affine_transform = rasterio.transform.AffineTransformer(src.transform)\n",
    "            transformer = Transformer.from_crs(CRS.from_epsg(4326), src.crs, always_xy=True)\n",
    "            x_chip, y_chip = transformer.transform(row['x'], row['y'])\n",
    "            x_offset, y_offset = affine_transform.rowcol(x_chip, y_chip)\n",
    "            \n",
    "            if 0 <= x_offset < width and 0 <= y_offset < height:\n",
    "                return src.read(1)[x_offset, y_offset], file\n",
    "    return (np.nan, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa64f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.read_csv(\"hls_submission.csv\")\n",
    "submission_df[['prediction', 'filename']] = submission_df.apply(get_prediction_value, axis=1, result_type='expand')\n",
    "submission_df.to_csv(\"hls_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33fb43d",
   "metadata": {},
   "source": [
    "**Upload submission file to Kaggle to see leaderboard score**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a73d79-f69f-4fb8-aa63-768ee3ee47ea",
   "metadata": {
    "id": "b9a73d79-f69f-4fb8-aa63-768ee3ee47ea"
   },
   "source": [
    "**Run Inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YgxyC5GnvjJU",
   "metadata": {
    "collapsed": true,
    "id": "YgxyC5GnvjJU",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !gsutil cp gs://instageo/utils/africa_prediction_template.csv .\n",
    "!mkdir -p inference/2021-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30afd0-73ec-4eb1-b9c1-a2d36475eae7",
   "metadata": {
    "id": "9c30afd0-73ec-4eb1-b9c1-a2d36475eae7"
   },
   "source": [
    "**Create Inference Data**\n",
    "\n",
    "For inference, we only need to download the necessary HLS tiles and run inference directly using the sliding window inference feature.\n",
    "\n",
    "If you're running inference across the entire African continent, you can use the `africa_prediction_template.csv`, which will automatically download 2,120 HLS granules covering Africa and parts of Asia.\n",
    "\n",
    "For this demo, we'll limit the scope to the HLS granules included in our test split.\n",
    "\n",
    "Note: Ensure you have approximately 1TB of storage space available for this process if you are running inference across Africa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f76b3ea-8ef7-473b-8f2e-72d493fdba03",
   "metadata": {
    "collapsed": true,
    "id": "8f76b3ea-8ef7-473b-8f2e-72d493fdba03",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !python -m \"instageo.data.chip_creator\" \\\n",
    "#     --dataframe_path=\"africa_prediction_template.csv\" \\\n",
    "#     --output_directory=\"inference/2021-06\" \\\n",
    "#     --min_count=1 \\\n",
    "#     --no_data_value=-1 \\\n",
    "#     --temporal_tolerance=3 \\\n",
    "#     --temporal_step=30 \\\n",
    "#     --num_steps=3 \\\n",
    "#     --download_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ku-49mTIqWvW",
   "metadata": {
    "id": "ku-49mTIqWvW"
   },
   "outputs": [],
   "source": [
    "# Instead of downloading new set of HLS tiles, we can use the one for our test split for inference.\n",
    "\n",
    "!cp -r test/* inference/2021-06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e86341-0717-458f-b061-3e957ce8536d",
   "metadata": {
    "id": "65e86341-0717-458f-b061-3e957ce8536d"
   },
   "source": [
    "**Run Inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a510ba",
   "metadata": {
    "id": "80a510ba"
   },
   "source": [
    "Adjust the `checkpoint_path` argument to use the desired model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JJXq8oWNAr1w",
   "metadata": {
    "id": "JJXq8oWNAr1w",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python -m instageo.model.run --config-name=locust \\\n",
    "    root_dir='inference/2021-06' \\\n",
    "    test_filepath='hls_dataset.json' \\\n",
    "    train.batch_size=16 \\\n",
    "    test.mask_cloud=True \\\n",
    "    checkpoint_path='checkpoint-path' \\\n",
    "    mode=predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d79e412-8176-411a-8a73-6068e22a0d25",
   "metadata": {
    "id": "8d79e412-8176-411a-8a73-6068e22a0d25"
   },
   "source": [
    "## InstaGeo - Apps\n",
    "Once inference has been completed on the HLS tiles and the results have been saved, we can use the `InstaGeo-Apps` module to visualize the predictions on an interactive map.\n",
    "\n",
    "To visualize the results, simply move the HLS prediction GeoTIFF files to the appropriate directory, and `InstaGeo-Apps` will handle the rest, providing an intuitive and interactive mapping experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a904882-cde9-40c8-affb-f988892e5183",
   "metadata": {
    "id": "8a904882-cde9-40c8-affb-f988892e5183",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p predictions/2023/6\n",
    "!mv inference/2023-06/predictions/* /content/predictions/2023/6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tQGnk67MY6Cd",
   "metadata": {
    "id": "tQGnk67MY6Cd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BeJsQzkeBNm7",
   "metadata": {
    "collapsed": true,
    "id": "BeJsQzkeBNm7",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nohup streamlit run InstaGeo-E2E-Geospatial-ML/instageo/apps/app.py --server.address=localhost &"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48459844-9277-473b-8cd8-e47691c59c0a",
   "metadata": {
    "id": "48459844-9277-473b-8cd8-e47691c59c0a"
   },
   "source": [
    "Retrieve your IP address which is the password of the localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S5rCS-lVZiWe",
   "metadata": {
    "id": "S5rCS-lVZiWe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "print(\"Password/Endpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bB61RRBNY-48",
   "metadata": {
    "id": "bB61RRBNY-48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!npx localtunnel --port 8501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7d922e",
   "metadata": {
    "id": "9f7d922e"
   },
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we demonstrated the end-to-end capabilities of InstaGeo for geospatial machine learning using multispectral data. We began by downloading and processing HLS granules, creating data chips for training, and fine-tuning a model with the Prithvi backbone. Finally, we ran inference on test data and visualized the results using the `InstaGeo-Apps` module.\n",
    "\n",
    "By leveraging InstaGeo, complex tasks such as data preprocessing, model training, and large-scale inference can be streamlined and efficiently handled with minimal configuration.\n",
    "\n",
    "If you found this demo helpful, please consider giving our [InstaGeo GitHub repository](https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML) a star ⭐! Your support helps us continue improving the tool for the community.\n",
    "\n",
    "Thank you for exploring InstaGeo with us!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316908ce",
   "metadata": {
    "id": "316908ce"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": ".m126",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/:m126"
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
